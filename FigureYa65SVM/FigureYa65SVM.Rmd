---
title: "FigureYa65SVM"
author: "小丫画图出品"
date: "2019-1-6"
output: html_document
---
欢迎关注“小丫画图”公众号，同名知识星球等你加入

小丫微信: epigenomics  E-mail: figureya@126.com

作者：Qi Delong

编辑校验：Liyin、小丫

注释：Qi Delong; Liyin

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 需求描述

利用svm-rfe和lasso logistic regression进行特征变量筛选，重现原文方法

![](example.png)

出自<http://ascopubs.org/doi/full/10.1200/JCO.2016.68.2153>

## 应用场景

svm-rfe（support vector machine - recursive feature elimination）是基于支持向量机的机器学习方法，
通过删减svm产生的特征向量来寻找最佳变量。

lasso lr（logistic regression）也是机器学习的方法之一，通过寻找分类错误最小时的λ来确定变量。

主要用于筛选特征变量，构建最佳分类模型。

## 环境设置

```{r, message=FALSE}
#options("repos"= c(CRAN="https://mirrors.tuna.tsinghua.edu.cn/CRAN/"))
#options(BioC_mirror="http://mirrors.ustc.edu.cn/bioc/")
#install.packages("glmnet") 
#if (!requireNamespace("BiocManager", quietly = TRUE))
    #install.packages("BiocManager")
#BiocManager::install("sigFeature", version = "3.8") 

library(tidyverse)
library(glmnet)
source('msvmRFE.R')   #文件夹内自带
library(VennDiagram)
library(sigFeature)
library(e1071)
library(caret)
library(randomForest)
```

## 输入文件

easy_input.csv，带有分组信息的矩阵。此处用例文自带的GSE75041，经过处理后得到，处理过程见文件夹中的HowToGetEasyInput.R。

可自行准备，至少包含以下信息：

- 第一列：sample ID
- 第二列：样本分组信息，最好为二分类变量
- 第三列之后：表达矩阵

```{r}
train <- read.csv("easy_input.csv",row.names = 1, 
                  as.is = F) #后面svmRFE函数要求group的类型为factor

dim(train)
train[1:4,1:4]
```

下面就以train作为输入，分别进行lasso和SVM-REF的变量筛选

## 图A，用LASSO-logitstic-Algorithm进行特征选择

### 找特征

```{r}
# 转为lasso需要的格式
x <- as.matrix(train[,-1])  
(y <- ifelse(train$group == "NR", 0,1)) #把分组信息换成01

#library(glmnet)
fit = glmnet(x, y, family = "binomial", alpha = 1, lambda = NULL)

# 画A图
#pdf("A_lasso.pdf", width = 5, height = 5)
plot(fit, xvar = "dev", label = TRUE)
#dev.off()
```
**注**：lasso图的更多细节调整，请参考FigureYa31lasso，例如在lasso图的线旁边显示特征名称，或用图例显示特征名称。

```{r}
cvfit = cv.glmnet(x, y, 
                  nfold=10, #例文描述：10-fold cross-validation
                  family = "binomial", type.measure = "class")
plot(cvfit)

cvfit$lambda.min #查看最佳lambda

# 获取LASSO选出来的特征
myCoefs <- coef(cvfit, s="lambda.min");
lasso_fea <- myCoefs@Dimnames[[1]][which(myCoefs != 0 )]
(lasso_fea <- lasso_fea[-1])

# 把lasso找到的特征保存到文件
write.csv(lasso_fea,"feature_lasso.csv")
```

### 效果评估

```{r}
# 使用选出来的特征进行模型的预测
# 因为没有验证数据，这里用了训练数据
predict <- predict(cvfit, newx = x[1:nrow(x),], s = "lambda.min", type = "class")
table(predict,y)
```

看到此处预测的准确性是百分之百，实际操作时还是要找测试集来做检验。

## 图B，使用SVM-REF-Algorithm-进行特征选择

例文用的是e1071包，参考资料：

- johncolby的代码：<https://github.com/johncolby/SVM-RFE>
- <http://www.colbyimaging.com/wiki/statistics/msvm-rfe>

### 找特征

```{r, message=FALSE}
#library(e1071)
#source(msvmRFE.R)
input <- train

#采用五折交叉验证 (k-fold crossValidation）
svmRFE(input, k = 5, halve.above = 100) #分割数据，分配随机数
nfold = 5
nrows = nrow(input)
folds = rep(1:nfold, len=nrows)[sample(nrows)]
folds = lapply(1:nfold, function(x) which(folds == x))
results = lapply(folds, svmRFE.wrap, input, k=5, halve.above=100) #特征选择

top.features = WriteFeatures(results, input, save=F) #查看主要变量
head(top.features)

#把SVM-REF找到的特征保存到文件
write.csv(top.features,"feature_svm.csv")
```

### 效果评估（Estimate generalization error）

> Each featsweep list element corresponds to using that many of the top features (i.e. featsweep[1] is using only the top feature, featsweep[2] is using the top 2 features, etc.). Within each, svm.list contains the generalization error estimates for each of the 10 folds in the external 5-fold CV. These accuracies are averaged as error.

测试300个变量时运行了大概9个小时(16G-台式机)

```{r}
# 运行时间主要取决于选择变量的个数，一般的电脑还是不要选择太多变量
# 选前5个变量进行SVM模型构建，体验一下
#featsweep = lapply(1:5, FeatSweep.wrap, results, input) #5个变量
#featsweep

# 选前300个变量进行SVM模型构建，然后导入已经运行好的结果
#featsweep = lapply(1:300, FeatSweep.wrap, results, input) #300个变量
#save(featsweep,file = "featsweep.RData")
(load("featsweep.RData"))

# 画图
no.info = min(prop.table(table(input[,1])))
errors = sapply(featsweep, function(x) ifelse(is.null(x), NA, x$error))

#dev.new(width=4, height=4, bg='white')
#pdf("B_svm-error.pdf",width = 5,height = 5)
PlotErrors(errors, no.info=no.info) #查看错误率
#dev.off()

#dev.new(width=4, height=4, bg='white')
#pdf("B_svm-accuracy.pdf",width = 5,height = 5)
Plotaccuracy(1-errors,no.info=no.info) #查看准确率
#dev.off()

# 图中红色圆圈所在的位置，即错误率最低点
which.min(errors) 
```

### 比较lasso和SVM-REF方法一找出的特征变量，画Venn图

```{r}
(myoverlap <- intersect(lasso_fea, top.features[1:which.min(errors), "FeatureName"])) #交集
summary(lasso_fea%in%top.features[1:which.min(errors), "FeatureName"]) 

#pdf("C_lasso_SVM_venn.pdf", width = 5, height = 3)
grid.newpage()
venn.plot <- venn.diagram(list(LASSO = lasso_fea, #画图
                               SVM_RFE = as.character(top.features[1:which.min(errors),"FeatureName"])), NULL, 
                          fill = c("#E31A1C","#E7B800"), 
                          alpha = c(0.5,0.5), cex = 4, cat.fontface=3, 
                          category.names = c("LASSO", "SVM_RFE"), 
                          main = "Overlap")
grid.draw(venn.plot)
#dev.off()
```

## 跟例文的结果对比

example_lasso.txt，例文用lasso找出来的特征

example_SVM-RFE.txt，例文用SVM-RFE找出来的特征

```{r}
# lasso结果对比
ex_lasso <- read.table("example_lasso.txt")
dim(ex_lasso)
intersect(lasso_fea, ex_lasso$V1)
summary(lasso_fea%in%ex_lasso$V1) 

# SVM结果对比
ex_SVM <- read.table("example_SVM-RFE.txt")
dim(ex_SVM)
intersect(top.features[1:which.min(errors), "FeatureName"], ex_SVM$V1)
summary(top.features[1:which.min(errors), "FeatureName"]%in%ex_SVM$V1)

# overlap对比
ex_overlap <- read.table("example_overlap.txt")
dim(ex_overlap)
intersect(myoverlap, ex_overlap$V1)
summary(myoverlap%in%ex_overlap$V1)
```

重合度非常低，小伙伴一起探讨吧！

## 附

SVM-RFE算法有多套代码可以实现，这里提供了另外两种SVM-REF-Algorithm的实现方法。

实际操作中可分别运行，对比效果，然后选其一。

见Lasso-SVM-REF-algorithm-Feature selection.R文件中的方法二和方法三。

```{r}
sessionInfo()
```
